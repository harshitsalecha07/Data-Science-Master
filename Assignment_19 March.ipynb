{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321c066e",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
    "\n",
    "Min-Max scaling is a data preprocessing technique used to transform numerical features in a dataset to a specific range, typically between 0 and 1. It's done by scaling the data so that the minimum value becomes 0, the maximum value becomes 1, and all other values are linearly interpolated between these two points. The formula for Min-Max scaling is:\n",
    "\n",
    "\\[X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}\\]\n",
    "\n",
    "Where:\n",
    "- \\(X_{scaled}\\) is the scaled value.\n",
    "- \\(X\\) is the original value.\n",
    "- \\(X_{min}\\) is the minimum value in the feature.\n",
    "- \\(X_{max}\\) is the maximum value in the feature.\n",
    "\n",
    "Example:\n",
    "Let's say you have a dataset of house prices with values ranging from $50,000 to $1,000,000. By applying Min-Max scaling, you can transform these prices to a range of 0 to 1. For a house priced at $200,000, the scaled value would be:\n",
    "\n",
    "\\[X_{scaled} = \\frac{200,000 - 50,000}{1,000,000 - 50,000} = 0.15\\]\n",
    "\n",
    "So, the scaled value for this house would be 0.15.\n",
    "\n",
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
    "\n",
    "The Unit Vector technique in feature scaling is also known as \"Normalization.\" Unlike Min-Max scaling, which scales data to a specific range, normalization scales data to have a magnitude of 1. It's often used in machine learning when the magnitude of the features is not important, but the direction (relative values) matters. The formula for normalization is:\n",
    "\n",
    "\\[X_{normalized} = \\frac{X}{\\|X\\|}\\]\n",
    "\n",
    "Where:\n",
    "- \\(X_{normalized}\\) is the normalized vector.\n",
    "- \\(X\\) is the original vector.\n",
    "- \\(\\|X\\|\\) represents the magnitude (Euclidean norm) of the vector \\(X\\).\n",
    "\n",
    "Example:\n",
    "Suppose you have a dataset with two features: \"Height\" and \"Weight.\" You want to normalize these features. If a person's height is 180 cm and weight is 75 kg, the normalized values would be:\n",
    "\n",
    "\\[Height_{normalized} = \\frac{180}{\\sqrt{180^2 + 75^2}} \\approx 0.964\\]\n",
    "\\[Weight_{normalized} = \\frac{75}{\\sqrt{180^2 + 75^2}} \\approx 0.266\\]\n",
    "\n",
    "\n",
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique used in data analysis and machine learning. It aims to reduce the number of features (or dimensions) in a dataset while preserving as much of the original information as possible. PCA identifies new axes (principal components) in the data space, and data points are projected onto these components.\n",
    "\n",
    "Example:\n",
    "Suppose you have a dataset with various measurements related to the physical characteristics of cars, such as horsepower, fuel efficiency, and dimensions. By applying PCA, you can reduce these multiple features to a smaller set of uncorrelated variables (principal components), making it easier to analyze and visualize the data.\n",
    "\n",
    "\n",
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "PCA can be used for feature extraction by transforming the original features into a set of orthogonal (uncorrelated) principal components. These principal components are linear combinations of the original features, and they capture the most significant variations in the data. Feature extraction using PCA is particularly useful when you have a high-dimensional dataset with correlated features.\n",
    "\n",
    "Example:\n",
    "Consider a dataset of images, each represented as a vector of pixel values. Instead of using each pixel as a separate feature, PCA can be applied to extract a reduced set of principal components that represent the most important patterns in the images. These principal components can then be used as features for further analysis or modeling.\n",
    "\n",
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
    "\n",
    "To preprocess the data for a food delivery recommendation system, you can use Min-Max scaling as follows:\n",
    "\n",
    "1. Identify the numerical features in your dataset, such as price, rating, and delivery time.\n",
    "\n",
    "2. For each numerical feature, calculate the minimum (\\(X_{min}\\)) and maximum (\\(X_{max}\\)) values within that feature across the entire dataset.\n",
    "\n",
    "3. Use the Min-Max scaling formula to scale each feature to a range between 0 and 1:\n",
    "\n",
    "   \\[X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}\\]\n",
    "\n",
    "4. Replace the original values of each feature with their corresponding scaled values.\n",
    "\n",
    "This preprocessing step ensures that all numerical features have the same scale, making it easier for machine learning algorithms to work with the data, as they are less sensitive to the magnitude of the features.\n",
    "\n",
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
    "\n",
    "\n",
    "To reduce the dimensionality of a dataset containing many features, such as company financial data and market trends for predicting stock prices, you can use PCA as follows:\n",
    "\n",
    "1. Standardize the data: Ensure that all features have zero mean and unit variance by subtracting the mean and dividing by the standard deviation of each feature.\n",
    "\n",
    "2. Calculate the covariance matrix of the standardized data.\n",
    "\n",
    "3. Compute the eigenvectors and eigenvalues of the covariance matrix.\n",
    "\n",
    "4. Sort the eigenvectors in descending order of their corresponding eigenvalues. These eigenvectors represent the principal components.\n",
    "\n",
    "5. Choose a suitable number of principal components to retain based on the explained variance. You can calculate the explained variance for each component and decide how many components to keep to capture a sufficient amount of variance.\n",
    "\n",
    "6. Project the original data onto the selected principal components to obtain a lower-dimensional representation of the data.\n",
    "\n",
    "By reducing the dimensionality, you can simplify the model, reduce noise, and potentially improve the performance of your stock price prediction model.\n",
    "\n",
    "\n",
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n",
    "\n",
    "\n",
    "To perform Min-Max scaling on the dataset [1, 5, 10, 15, 20] to transform the values to a range of -1 to 1, follow these steps:\n",
    "\n",
    "1. Calculate the minimum (\\(X_{min}\\)) and maximum (\\(X_{max}\\)) values in the dataset:\n",
    "   - \\(X_{min} = 1\\)\n",
    "   - \\(X_{max} = 20\\)\n",
    "\n",
    "2. Apply the Min-Max scaling formula to each value in the dataset:\n",
    "\n",
    "   \\[X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}\\]\n",
    "\n",
    "   - For 1: \\(\\frac{1 - 1}{20 - 1} = 0\\)\n",
    "   - For 5: \\(\\frac{5 - 1}{20 - 1} \\approx 0.176\\)\n",
    "   - For 10: \\(\\frac{10 - 1}{20 - 1} \\approx 0.441\\)\n",
    "   - For 15: \\(\\frac{15 - 1}{20 - 1} \\approx 0.706\\)\n",
    "   - For 20: \\(\\frac{20 - 1}{20 - 1} = 1\\)\n",
    "\n",
    "So, the Min-Max scaled values for the dataset are [-1, -0.648, -0.118, 0.412, 1].\n",
    "\n",
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "To perform feature extraction using PCA on the dataset with features [height, weight, age, gender, blood pressure], you would follow these steps:\n",
    "\n",
    "1. Standardize the data: Ensure that all features have zero mean and unit variance by\n",
    "\n",
    " subtracting the mean and dividing by the standard deviation of each feature.\n",
    "\n",
    "2. Calculate the covariance matrix of the standardized data.\n",
    "\n",
    "3. Compute the eigenvectors and eigenvalues of the covariance matrix.\n",
    "\n",
    "4. Sort the eigenvectors in descending order of their corresponding eigenvalues. These eigenvectors represent the principal components.\n",
    "\n",
    "5. Examine the explained variance associated with each principal component. You can create a cumulative explained variance plot to help decide how many principal components to retain.\n",
    "\n",
    "6. Choose a suitable number of principal components to retain based on the explained variance. A common rule of thumb is to retain enough components to capture a significant portion (e.g., 95%) of the total variance.\n",
    "\n",
    "The number of principal components you choose to retain would depend on the specific dataset and your desired level of dimensionality reduction. It's a trade-off between reducing dimensionality and retaining as much information as possible. Typically, you would choose a number that strikes a balance between these two objectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459de61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
